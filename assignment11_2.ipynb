{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment11-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOD0Bfwwr03GgkIWcvVnA9L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlguswn3659/class-MachineLearning/blob/master/assignment11_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt9Wj3kH5q8w",
        "colab_type": "code",
        "outputId": "b5b0638b-7f70-4497-d397-b59383bee7de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.datasets import load_files\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import pickle\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "import zipfile\n",
        "import io\n",
        "zf = zipfile.ZipFile(io.BytesIO(uploaded['movie_review.zip']), \"r\")\n",
        "zf.extractall()\n",
        "\n",
        "review_data = load_files(r\"movie_review\")\n",
        "X, y = review_data.data, review_data.target\n",
        "\n",
        "documents = []\n",
        "\n",
        "stemmer = WordNetLemmatizer()\n",
        "\n",
        "for sen in range(0, len(X)):\n",
        "    # Remove all the special characters\n",
        "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
        "    \n",
        "    # remove all single characters\n",
        "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "    \n",
        "    # Remove single characters from the start\n",
        "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
        "    \n",
        "    # Substituting multiple spaces with single space\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "    \n",
        "    # Removing prefixed 'b'\n",
        "    document = re.sub(r'^b\\s+', '', document)\n",
        "    \n",
        "    # Converting to Lowercase\n",
        "    document = document.lower()\n",
        "    \n",
        "    # Lemmatization\n",
        "    document = document.split()\n",
        "    document = [stemmer.lemmatize(word) for word in document]\n",
        "    document = ' '.join(document)\n",
        "    \n",
        "    documents.append(document)\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "X = vectorizer.fit_transform(documents).toarray()\n",
        "\n",
        "tfidfconverter = TfidfTransformer()\n",
        "X = tfidfconverter.fit_transform(X).toarray()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQpyXu3jGOvY",
        "colab_type": "code",
        "outputId": "54c1f076-2d47-4571-dd95-78ebfccb2558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        }
      },
      "source": [
        "print(X_train)\n",
        "print(X_test)\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         ... 0.         0.03211483 0.        ]\n",
            " [0.         0.         0.         ... 0.         0.08401884 0.        ]\n",
            " [0.         0.         0.         ... 0.06909913 0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.03917949 0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.05031797 0.         ... 0.         0.03543396 0.        ]]\n",
            "[[0.         0.         0.         ... 0.19464767 0.         0.07702493]\n",
            " [0.05225032 0.         0.05418345 ... 0.04473471 0.         0.        ]\n",
            " [0.         0.10246644 0.         ... 0.10573626 0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.03878449 0.        ]]\n",
            "[0 0 1 ... 1 0 1]\n",
            "[1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0\n",
            " 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 0 0\n",
            " 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0\n",
            " 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0\n",
            " 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 1\n",
            " 1 1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0\n",
            " 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0 0\n",
            " 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1\n",
            " 0 0 0 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0\n",
            " 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1\n",
            " 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1\n",
            " 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
            " 1 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1\n",
            " 1 1 1 0 0 1 1 0 0]\n",
            "(1401, 1500)\n",
            "(601, 1500)\n",
            "(1401,)\n",
            "(601,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSA68oWdBX2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_classifier에 대한 함수 정의하기\n",
        "# def train_classifier(X_Train, y_Train):\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD42xdkL05UT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Codes for classification\n",
        "\n",
        "# classifier = train_classifier(X_train, y_train)\n",
        "# y_pred_test = classifier.predict(X_test)\n",
        "# y_pred_train = classifier.predict(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV9K1MVaET0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_t = np.zeros((350, 1501))  #350줄\n",
        "matrix_t[0][0] = 1               #y레이어의 bias를 위한 값 1\n",
        "\n",
        "for i in range(1, 350):\n",
        "  for j in range(0, 1501):\n",
        "    matrix_t[i][j] = np.random.normal()\n",
        "\n",
        "\n",
        "# matrix_u[196][0] = 0            #줄, 칸\n",
        "##############################################\n",
        "matrix_u = np.zeros((50, 350))  #50줄\n",
        "matrix_u[0][0] = 1               #y레이어의 bias를 위한 값 1\n",
        "\n",
        "for i in range(1, 50):\n",
        "  for j in range(0, 350):\n",
        "    matrix_u[i][j] = np.random.normal()\n",
        "\n",
        "\n",
        "# matrix_u[196][0] = 0            #줄, 칸\n",
        "##############################################\n",
        "matrix_v = np.zeros((8, 50))  #8줄\n",
        "matrix_v[0][0] = 1               #y레이어의 bias를 위한 값 1\n",
        "\n",
        "for i in range(1, 8):\n",
        "  for j in range(0, 50):\n",
        "    matrix_v[i][j] = np.random.normal()\n",
        "\n",
        "\n",
        "# matrix_v[196][0] = 0            #줄, 칸\n",
        "##############################################\n",
        "matrix_w = np.zeros((1, 8))  #1줄\n",
        "\n",
        "for i in range(0, 1):\n",
        "  for j in range(0, 8):\n",
        "    matrix_w[i][j] = np.random.normal()\n",
        "\n",
        "# matrix_w[196][0] = 0            #줄, 칸\n",
        "\n",
        "# print(matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfHkfVcXRZIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "import matplotlib.animation as animation\n",
        "import operator\n",
        "from scipy import stats \n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.datasets.samples_generator import make_regression \n",
        "import csv\n",
        "import math\n",
        "import statistics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLiiakUcEfil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator\n",
        "\n",
        "x_ = np.ones((350, 1))\n",
        "y_ = np.ones((50, 1))\n",
        "\n",
        "j_list = np.ones(shape=(1401, 1501, 1))\n",
        "x_list = np.ones(shape=(1401, 350, 1))\n",
        "\n",
        "x__list = np.ones(shape=(1401, 350, 1))\n",
        "y__list = np.ones(shape=(1401, 50, 1))\n",
        "z__list = np.ones(shape=(1401, 8, 1))\n",
        "h__list = np.ones(shape=(1401, 1, 1))\n",
        "\n",
        "x_list = np.ones(shape=(1401, 350, 1))\n",
        "y_list = np.ones(shape=(1401, 50, 1))\n",
        "z_list = np.ones(shape=(1401, 8, 1))\n",
        "h_list = np.ones(shape=(1401, 1, 1))\n",
        "l_list = np.zeros(shape=(1401, 1, 1))\n",
        "\n",
        "x_list_tmp = np.ones(shape=(1401, 350, 1))\n",
        "y_list_tmp = np.ones(shape=(1401, 50, 1))\n",
        "z_list_tmp = np.ones(shape=(1401, 8, 1))\n",
        "h_list_tmp = np.ones(shape=(1401, 1, 1))\n",
        "\n",
        "x__list_tmp = np.ones(shape=(1401, 350, 1))\n",
        "y__list_tmp = np.ones(shape=(1401, 50, 1))\n",
        "z__list_tmp = np.ones(shape=(1401, 8, 1))\n",
        "h__list_tmp = np.ones(shape=(1401, 1, 1))\n",
        "\n",
        "\n",
        "#training set 1401개에 대해서\n",
        "for i in range(0, 1401):  \n",
        "  bias   = [1]       #bias 1\n",
        "  im_vector = np.concatenate((bias, X_train[i]), axis = None)\n",
        "  j_list[i] = im_vector.reshape((1501, 1))\n",
        "\n",
        "  x_ = np.dot(matrix_t, j_list[i])  #x와 가중치 u를 곱해서 y_를 만듦\n",
        "  x__list[i] = x_\n",
        "  \n",
        "  x_vector = np.ones((350,1)) #bias\n",
        "  for j in range (1, 350):\n",
        "    x_vector[j][0] = 1 / (1 + math.exp(-x_[j][0]))\n",
        "    # sigmoid(y_[j][0])  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "  x   = x_vector.reshape((350, 1))\n",
        "  x_list[i] = x\n",
        "\n",
        "\n",
        "\n",
        "  y_ = np.dot(matrix_u, x)  #x와 가중치 u를 곱해서 y_를 만듦\n",
        "  y__list[i] = y_\n",
        "  \n",
        "  y_vector = np.ones((50,1)) #bias\n",
        "  for j in range (1, 50):\n",
        "    y_vector[j][0] = 1 / (1 + math.exp(-y_[j][0]))\n",
        "    # sigmoid(y_[j][0])  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "  y   = y_vector.reshape((50, 1))\n",
        "  y_list[i] = y\n",
        "\n",
        "  z_  = np.dot(matrix_v, y)  #y와 가중치 v를 곱해서 z_를 만듦\n",
        "  z__list[i] = z_\n",
        "  z_vector = np.ones((8,1)) #bias\n",
        "  for j in range (1, 8):\n",
        "    z_vector[j][0] = 1 / (1 + math.exp(-z_[j][0]))  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "  z   = z_vector.reshape((8, 1))\n",
        "  z_list[i] = z\n",
        "  \n",
        "  # print(z)\n",
        "\n",
        "  h_  = np.dot(matrix_w, z)  #z와 가중치 w를 곱해서 h_를 만듦\n",
        "  h__list[i] = h_\n",
        "  \n",
        "  h_vector = np.ones((1,1)) #bias\n",
        "  for j in range (0, 1):\n",
        "    h_vector[j][0] = 1 / (1 + math.exp(-h_[j][0]))  #sigmoid 함수를 적용해서 h_에서 h를 만듦\n",
        "\n",
        "  h   = h_vector.reshape((1, 1))\n",
        "  # tmp = h.ravel()\n",
        "  # max_value = max(tmp)\n",
        "  # print(max_value)\n",
        "  # max_index = tmp.index(max_value)\n",
        "  h_list[i] = h\n",
        "\n",
        "  tmp_label = 0\n",
        "  # print(h)\n",
        "\n",
        "  if h >= 0.5:\n",
        "    tmp_label = 1\n",
        "\n",
        "  l_list[i][0] = tmp_label\n",
        "  # print(l_list[i])\n",
        "  # print(h)\n",
        "\n",
        "  x_list_tmp[i] = x_list[i]\n",
        "  y_list_tmp[i] = y_list[i]\n",
        "  z_list_tmp[i] = z_list[i]\n",
        "  h_list_tmp[i] = h_list[i]\n",
        "  x__list_tmp[i] = x__list[i]\n",
        "  y__list_tmp[i] = y__list[i]\n",
        "  z__list_tmp[i] = z__list[i]\n",
        "  h__list_tmp[i] = h__list[i]\n",
        "\n",
        "# print(l_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b91lsWSoEg8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator\n",
        "\n",
        "x_2 = np.ones((350, 1))\n",
        "y_2 = np.ones((50, 1))\n",
        "\n",
        "j_list2 = np.ones(shape=(601, 1501, 1))\n",
        "x_list2 = np.ones(shape=(601, 350, 1))\n",
        "\n",
        "x__list2 = np.ones(shape=(601, 350, 1))\n",
        "y__list2 = np.ones(shape=(601, 50, 1))\n",
        "z__list2 = np.ones(shape=(601, 8, 1))\n",
        "h__list2 = np.ones(shape=(601, 1, 1))\n",
        "\n",
        "x_list2 = np.ones(shape=(601, 350, 1))\n",
        "y_list2 = np.ones(shape=(601, 50, 1))\n",
        "z_list2 = np.ones(shape=(601, 8, 1))\n",
        "h_list2 = np.ones(shape=(601, 1, 1))\n",
        "l_list2 = np.zeros(shape=(601, 1, 1))\n",
        "\n",
        "x_list_tmp2 = np.ones(shape=(601, 350, 1))\n",
        "y_list_tmp2 = np.ones(shape=(601, 50, 1))\n",
        "z_list_tmp2 = np.ones(shape=(601, 8, 1))\n",
        "h_list_tmp2 = np.ones(shape=(601, 1, 1))\n",
        "\n",
        "x__list_tmp2 = np.ones(shape=(601, 350, 1))\n",
        "y__list_tmp2 = np.ones(shape=(601, 50, 1))\n",
        "z__list_tmp2 = np.ones(shape=(601, 8, 1))\n",
        "h__list_tmp2 = np.ones(shape=(601, 1, 1))\n",
        "\n",
        "\n",
        "#training set 1401개에 대해서\n",
        "for i in range(0, 601):  \n",
        "  bias2   = [1]       #bias 1\n",
        "  im_vector2 = np.concatenate((bias2, X_test[i]), axis = None)\n",
        "  j_list2[i] = im_vector2.reshape((1501, 1))\n",
        "\n",
        "  x_2 = np.dot(matrix_t, j_list2[i])  #x와 가중치 u를 곱해서 y_를 만듦\n",
        "  x__list2[i] = x_2\n",
        "  \n",
        "  x_vector2 = np.ones((350,1)) #bias\n",
        "  for j in range (1, 350):\n",
        "    x_vector2[j][0] = 1 / (1 + math.exp(-x_2[j][0]))\n",
        "    # sigmoid(y_[j][0])  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "  x2   = x_vector2.reshape((350, 1))\n",
        "  x_list2[i] = x2\n",
        "\n",
        "\n",
        "\n",
        "  y_2 = np.dot(matrix_u, x2)  #x와 가중치 u를 곱해서 y_를 만듦\n",
        "  y__list2[i] = y_2\n",
        "  \n",
        "  y_vector2 = np.ones((50,1)) #bias\n",
        "  for j in range (1, 50):\n",
        "    y_vector2[j][0] = 1 / (1 + math.exp(-y_2[j][0]))\n",
        "    # sigmoid(y_[j][0])  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "  y2   = y_vector2.reshape((50, 1))\n",
        "  y_list2[i] = y2\n",
        "\n",
        "  z_2  = np.dot(matrix_v, y2)  #y와 가중치 v를 곱해서 z_를 만듦\n",
        "  z__list2[i] = z_2\n",
        "  z_vector2 = np.ones((8,1)) #bias\n",
        "  for j in range (1, 8):\n",
        "    z_vector2[j][0] = 1 / (1 + math.exp(-z_2[j][0]))  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "  z2   = z_vector2.reshape((8, 1))\n",
        "  z_list2[i] = z2\n",
        "  \n",
        "  # print(z)\n",
        "\n",
        "  h_2 = np.dot(matrix_w, z2)  #z와 가중치 w를 곱해서 h_를 만듦\n",
        "  h__list2[i] = h_2\n",
        "  \n",
        "  h_vector2 = np.ones((1,1)) #bias\n",
        "  for j in range (0, 1):\n",
        "    h_vector2[j][0] = 1 / (1 + math.exp(-h_2[j][0]))  #sigmoid 함수를 적용해서 h_에서 h를 만듦\n",
        "\n",
        "  h2   = h_vector2.reshape((1, 1))\n",
        "  # tmp = h.ravel()\n",
        "  # max_value = max(tmp)\n",
        "  # print(max_value)\n",
        "  # max_index = tmp.index(max_value)\n",
        "  h_list2[i] = h2\n",
        "\n",
        "  tmp_label = 0\n",
        "\n",
        "  if h2 >= 0.5:\n",
        "    tmp_label = 1\n",
        "\n",
        "  l_list2[i][0] = tmp_label\n",
        "  # print(l_list[i])\n",
        "  # print(h2)\n",
        "\n",
        "  x_list_tmp2[i] = x_list2[i]\n",
        "  y_list_tmp2[i] = y_list2[i]\n",
        "  z_list_tmp2[i] = z_list2[i]\n",
        "  h_list_tmp2[i] = h_list2[i]\n",
        "  x__list_tmp2[i] = x__list2[i]\n",
        "  y__list_tmp2[i] = y__list2[i]\n",
        "  z__list_tmp2[i] = z__list2[i]\n",
        "  h__list_tmp2[i] = h__list2[i]\n",
        "\n",
        "# print(l_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVgg5PyfCGAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d908a85-4ef8-4b16-a986-6344af8e8f7c"
      },
      "source": [
        "# (1401, 1500)\n",
        "# (601, 1500)\n",
        "# (1401,)\n",
        "# (601,)\n",
        "\n",
        "iteration = 10\n",
        "l_r = 0.1\n",
        "lambda_ = 1\n",
        "\n",
        "cost_history = np.zeros(iteration)    #about train\n",
        "cost_history2 = np.zeros(iteration)   #about test\n",
        "\n",
        "label_group = np.zeros(shape = (1401, 1))\n",
        "label_group2 = np.zeros(shape = (601, 1))\n",
        "\n",
        "for i in range(0, 1401):\n",
        "  label_group[i][0] = l_list[i][0]\n",
        "\n",
        "for i in range(0, 601):\n",
        "  label_group2[i][0] = l_list2[i][0]\n",
        "\n",
        "for t in range(0, iteration):\n",
        "  print(t, end=' ')\n",
        "\n",
        "  parameter_sum = 0\n",
        "\n",
        "  for q in range(0, 1501):\n",
        "    for w in range(1, 350):\n",
        "      parameter_sum = parameter_sum + matrix_t[w][q]**2\n",
        "\n",
        "  for q in range(0, 350):\n",
        "    for w in range(1, 50):\n",
        "      parameter_sum = parameter_sum + matrix_u[w][q]**2\n",
        "\n",
        "  for q in range(0, 50):\n",
        "    for w in range(1, 8):\n",
        "      parameter_sum = parameter_sum + matrix_v[w][q]**2\n",
        "\n",
        "  for q in range(0, 8):\n",
        "    for w in range(0, 1):\n",
        "      parameter_sum = parameter_sum + matrix_w[w][q]**2\n",
        "\n",
        "  result = 0.0\n",
        "  for i in range(0, 1401):\n",
        "    for k in range(0, 1):\n",
        "      result = result + ((-1)*label_group[i][k]*math.log(h_list[i][k][0]) - (1-label_group[i][k])*math.log(1-h_list[i][k][0])) + ((lambda_)/(2 * 543258)) * parameter_sum\n",
        "  result = result / 1401\n",
        "  cost_history[t] = result\n",
        "\n",
        "##gradient descent\n",
        "  result_w = 0\n",
        "  result_v = 0\n",
        "  result_u = 0\n",
        "  result_t = 0\n",
        "\n",
        "  for i in range(0, 1401):\n",
        "    small_delta_2 = np.zeros(shape = (1, 1))\n",
        "    for j in range(0, 1):\n",
        "      small_delta_2[j][0] = h_list[i][j] - label_group[i][j]\n",
        "    # print(h_list[i])\n",
        "    # print(label_group[i])\n",
        "    # small_delta_2 = h_list[i] - label_group[i] #여기 label_group 다시 봐야함.\n",
        "    small_delta_1 = np.dot(np.transpose(matrix_w), small_delta_2)\n",
        "    small_delta_0 = np.dot(np.transpose(matrix_v), small_delta_1)*(y_list_tmp[i]*(1 - y_list_tmp[i]))\n",
        "    small_delta_ = np.dot(np.transpose(matrix_u), small_delta_0)*(x_list_tmp[i]*(1 - x_list_tmp[i])) #이거..괜찮은가..?\n",
        "\n",
        "    # print(small_delta_2)\n",
        "    result_w = result_w + np.dot(small_delta_2, np.transpose(z_list[i]))\n",
        "    result_v = result_v + np.dot(small_delta_1, np.transpose(y_list[i]))\n",
        "    result_u = result_u + np.dot(small_delta_0, np.transpose(x_list[i]))\n",
        "    result_t = result_t + np.dot(small_delta_, np.transpose(j_list[i]))\n",
        "\n",
        "  matrix_w = matrix_w - (result_w / 1401 *l_r)\n",
        "  matrix_v = matrix_v - (result_v / 1401 *l_r)\n",
        "  matrix_u = matrix_u - (result_u / 1401 *l_r)\n",
        "  matrix_t = matrix_t - (result_t / 1401 *l_r)\n",
        "\n",
        "\n",
        "####################################################################\n",
        "\n",
        "  for k in range(0, 1401):\n",
        "    bias   = [1]       #bias 1\n",
        "    im_vector = np.concatenate((bias, X_train[k]), axis = None)\n",
        "    j_list[k] = im_vector.reshape((1501, 1))\n",
        "\n",
        "    x_ = np.dot(matrix_t, j_list[k])  #x와 가중치 u를 곱해서 y_를 만듦\n",
        "    x__list[k] = x_\n",
        "    \n",
        "    x_vector = np.ones((350,1)) #bias\n",
        "    for j in range (1, 350):\n",
        "      x_vector[j][0] = 1 / (1 + math.exp(-x_[j][0]))\n",
        "      # sigmoid(y_[j][0])  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "    x   = x_vector.reshape((350, 1))\n",
        "    x_list[k] = x\n",
        "\n",
        "\n",
        "\n",
        "    y_ = np.dot(matrix_u, x)  #x와 가중치 u를 곱해서 y_를 만듦\n",
        "    y__list[k] = y_\n",
        "    \n",
        "    y_vector = np.ones((50,1)) #bias\n",
        "    for j in range (1, 50):\n",
        "      y_vector[j][0] = 1 / (1 + math.exp(-y_[j][0]))\n",
        "      # sigmoid(y_[j][0])  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "    y   = y_vector.reshape((50, 1))\n",
        "    y_list[k] = y\n",
        "\n",
        "    z_  = np.dot(matrix_v, y)  #y와 가중치 v를 곱해서 z_를 만듦\n",
        "    z__list[k] = z_\n",
        "    z_vector = np.ones((8,1)) #bias\n",
        "    for j in range (1, 8):\n",
        "      z_vector[j][0] = 1 / (1 + math.exp(-z_[j][0]))  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "    z   = z_vector.reshape((8, 1))\n",
        "    z_list[k] = z\n",
        "    \n",
        "    # print(z)\n",
        "\n",
        "    h_  = np.dot(matrix_w, z)  #z와 가중치 w를 곱해서 h_를 만듦\n",
        "    h__list[k] = h_\n",
        "    \n",
        "    h_vector = np.ones((1,1)) #bias\n",
        "    for j in range (0, 1):\n",
        "      h_vector[j][0] = 1 / (1 + math.exp(-h_[j][0]))  #sigmoid 함수를 적용해서 h_에서 h를 만듦\n",
        "\n",
        "    h   = h_vector.reshape((1, 1))\n",
        "    # tmp = h.ravel()\n",
        "    # max_value = max(tmp)\n",
        "    # print(max_value)\n",
        "    # max_index = tmp.index(max_value)\n",
        "\n",
        "    h_list11_tmp = h_list.reshape((1401))\n",
        "    median_val = statistics.median(h_list11_tmp)\n",
        "\n",
        "    h_list[k] = h\n",
        "\n",
        "    tmp_label = 0\n",
        "\n",
        "    if h >= median_val:\n",
        "        # print(h)\n",
        "        tmp_label = 1\n",
        "\n",
        "    # if h >= 0.5:\n",
        "    #   # print(h)\n",
        "    #   tmp_label = 1\n",
        "\n",
        "    l_list[k][0] = tmp_label\n",
        "    # print(l_list[k])\n",
        "    # print(h)\n",
        "\n",
        "    x_list_tmp[k] = x_list[k]\n",
        "    y_list_tmp[k] = y_list[k]\n",
        "    z_list_tmp[k] = z_list[k]\n",
        "    h_list_tmp[k] = h_list[k]\n",
        "    x__list_tmp[k] = x__list[k]\n",
        "    y__list_tmp[k] = y__list[k]\n",
        "    z__list_tmp[k] = z__list[k]\n",
        "    h__list_tmp[k] = h__list[k]\n",
        "\n",
        "\n",
        "  # accuracy_history[t] = number_of_correct_predictions/total_number_of_predictions*100\n",
        "  # print(accuracy_history[t])\n",
        "\n",
        "############################\n",
        "  #test data!\n",
        "\n",
        "  number_of_correct_predictions2 = 0\n",
        "  \n",
        "  print(t, end=' ')\n",
        "\n",
        "  result2 = 0.0\n",
        "  for i in range(0, 601):\n",
        "    for k in range(0, 1):\n",
        "      # if h_list_tmp[i][k][0] <= 0:\n",
        "      # print(h_list_tmp[i][k][0])\n",
        "      result2 = result2 + ((-1)*label_group2[i][k]*math.log(h_list2[i][k][0]) - (1-label_group2[i][k])*math.log(1-h_list2[i][k][0])) + ((lambda_)/(2 * 164995)) * parameter_sum\n",
        "  result2 = result2 / 601\n",
        "  cost_history2[t] = result2\n",
        "\n",
        "\n",
        "  for k in range(0, 601):\n",
        "  # print(i)\n",
        "    bias2   = [1]       #bias 1\n",
        "    im_vector2 = np.concatenate((bias2, X_test[k]), axis = None)\n",
        "    j_list2[k] = im_vector2.reshape((1501, 1))\n",
        "\n",
        "    x_2 = np.dot(matrix_t, j_list2[k])  #x와 가중치 u를 곱해서 y_를 만듦\n",
        "    x__list2[k] = x_2\n",
        "    \n",
        "    x_vector2 = np.ones((350,1)) #bias\n",
        "    for j in range (1, 350):\n",
        "      x_vector2[j][0] = 1 / (1 + math.exp(-x_2[j][0]))\n",
        "      # sigmoid(y_[j][0])  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "    x2   = x_vector2.reshape((350, 1))\n",
        "    x_list2[k] = x2\n",
        "\n",
        "\n",
        "\n",
        "    y_2 = np.dot(matrix_u, x2)  #x와 가중치 u를 곱해서 y_를 만듦\n",
        "    y__list2[k] = y_2\n",
        "    \n",
        "    y_vector2 = np.ones((50,1)) #bias\n",
        "    for j in range (1, 50):\n",
        "      y_vector2[j][0] = 1 / (1 + math.exp(-y_2[j][0]))\n",
        "      # sigmoid(y_[j][0])  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "    y2   = y_vector2.reshape((50, 1))\n",
        "    y_list2[k] = y2\n",
        "\n",
        "    z_2  = np.dot(matrix_v, y2)  #y와 가중치 v를 곱해서 z_를 만듦\n",
        "    z__list2[k] = z_2\n",
        "    z_vector2 = np.ones((8,1)) #bias\n",
        "    for j in range (1, 8):\n",
        "      z_vector2[j][0] = 1 / (1 + math.exp(-z_2[j][0]))  #sigmoid 함수를 적용해서 y_에서 y를 만듦\n",
        "\n",
        "    z2   = z_vector2.reshape((8, 1))\n",
        "    z_list2[k] = z2\n",
        "    \n",
        "    # print(z)\n",
        "\n",
        "    h_2 = np.dot(matrix_w, z2)  #z와 가중치 w를 곱해서 h_를 만듦\n",
        "    h__list2[k] = h_2\n",
        "    \n",
        "    h_vector2 = np.ones((1,1)) #bias\n",
        "    for j in range (0, 1):\n",
        "      h_vector2[j][0] = 1 / (1 + math.exp(-h_2[j][0]))  #sigmoid 함수를 적용해서 h_에서 h를 만듦\n",
        "\n",
        "    h2   = h_vector2.reshape((1, 1))\n",
        "    # tmp = h.ravel()\n",
        "    # max_value = max(tmp)\n",
        "    # print(max_value)\n",
        "    # max_index = tmp.index(max_value)\n",
        "\n",
        "    h_list22_tmp = h_list2.reshape((601))\n",
        "    median_val2 = statistics.median(h_list22_tmp)\n",
        "\n",
        "    h_list2[k] = h2\n",
        "\n",
        "    tmp_label = 0\n",
        "\n",
        "    if h2 >= median_val2:\n",
        "      # print(h2)\n",
        "      tmp_label = 1\n",
        "\n",
        "    # if h2 >= 0.5:\n",
        "    #   # print(h2)\n",
        "    #   tmp_label = 1\n",
        "\n",
        "    l_list2[k][0] = tmp_label\n",
        "    # print(l_list[k])\n",
        "    # print(h2)\n",
        "\n",
        "    x_list_tmp2[k] = x_list2[k]\n",
        "    y_list_tmp2[k] = y_list2[k]\n",
        "    z_list_tmp2[k] = z_list2[k]\n",
        "    h_list_tmp2[k] = h_list2[k]\n",
        "    x__list_tmp2[k] = x__list2[k]\n",
        "    y__list_tmp2[k] = y__list2[k]\n",
        "    z__list_tmp2[k] = z__list2[k]\n",
        "    h__list_tmp2[k] = h__list2[k]\n",
        "\n",
        "  # accuracy_history2[t] = number_of_correct_predictions2/total_number_of_predictions2*100\n",
        "  t = t + 1"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtFVXgejZDIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "9072ccef-73a5-4175-8925-556c2b7a4147"
      },
      "source": [
        "#그 코드를 바탕으로 training loss plotting 하기.\n",
        "real_iter = iteration\n",
        "\n",
        "fig,ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "cost_tmp = np.zeros(real_iter)\n",
        "\n",
        "for i in range(0, real_iter):\n",
        "  cost_tmp[i] = cost_history[i]\n",
        "\n",
        "\n",
        "# print(cost_history[1])\n",
        "\n",
        "ax.set_ylabel('J(Theta)')\n",
        "ax.set_xlabel('Iterations')\n",
        "_=ax.plot(range(real_iter),cost_tmp,'b.', color = 'blue')\n",
        "_=ax.plot(range(real_iter),cost_history2,'b.', color = 'red')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuTRLc611Ayn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "366c16fe-f033-4439-a854-b676fc1c7f46"
      },
      "source": [
        "#Codes for Evaluation\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "l_list_tmp = l_list.reshape((1401))\n",
        "l_list2_tmp = l_list2.reshape((601))\n",
        "\n",
        "print(confusion_matrix(y_train,l_list_tmp))\n",
        "print(classification_report(y_train,l_list_tmp))\n",
        "print(accuracy_score(y_train, l_list_tmp))\n",
        "\n",
        "print(confusion_matrix(y_test,l_list2_tmp))\n",
        "print(classification_report(y_test,l_list2_tmp))\n",
        "print(accuracy_score(y_test, l_list2_tmp))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[315 384]\n",
            " [352 350]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.45      0.46       699\n",
            "           1       0.48      0.50      0.49       702\n",
            "\n",
            "    accuracy                           0.47      1401\n",
            "   macro avg       0.47      0.47      0.47      1401\n",
            "weighted avg       0.47      0.47      0.47      1401\n",
            "\n",
            "0.47466095645967166\n",
            "[[136 166]\n",
            " [149 150]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.45      0.46       302\n",
            "           1       0.47      0.50      0.49       299\n",
            "\n",
            "    accuracy                           0.48       601\n",
            "   macro avg       0.48      0.48      0.48       601\n",
            "weighted avg       0.48      0.48      0.48       601\n",
            "\n",
            "0.47587354409317806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDpSEICHtNlB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2343fe7-4d7c-4c87-aec8-294c88fb1efe"
      },
      "source": [
        "class_1 = 0\n",
        "\n",
        "for i in range(0, 601):\n",
        "  if l_list2_tmp[i] == 1:\n",
        "    class_1 = class_1 + 1\n",
        "\n",
        "print(class_1)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbPP4IIn3lMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "13cf9868-1112-4b72-c9bb-ed84cec57103"
      },
      "source": [
        "print(y_train)\n",
        "print(l_list_tmp)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 ... 1 0 1]\n",
            "[1. 0. 0. ... 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}