{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment06.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6FVp9oIWVqptdWGHJYooT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlguswn3659/class-MachineLearning/blob/master/assignment06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMcbWdbh98uY",
        "colab_type": "text"
      },
      "source": [
        "# **Machine Learning Assignment06** #\n",
        "\n",
        "Name : 이현주\n",
        "\n",
        "Student # : 20184060"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmK4D4Gm-Owm",
        "colab_type": "text"
      },
      "source": [
        "# **1. Plot the training data [2pt]**\n",
        "\n",
        "- plot the training data points (x,y) with their labels / in colors (blue for label 0 and red for label 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPQTutBY9LYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "7e0b9d7f-2c39-4a1f-bb41-41b133289b13"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "import matplotlib.animation as animation\n",
        "from scipy import stats \n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.datasets.samples_generator import make_regression \n",
        "import csv\n",
        "import math\n",
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "data    = np.genfromtxt(\"data-nonlinear.txt\", delimiter=',')\n",
        "\n",
        "pointX  = data[:, 0]\n",
        "pointY  = data[:, 1]\n",
        "label   = data[:, 2]\n",
        "\n",
        "pointX0 = pointX[label == 0]\n",
        "pointY0 = pointY[label == 0]\n",
        "\n",
        "pointX1 = pointX[label == 1]\n",
        "pointY1 = pointY[label == 1]\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(pointX0, pointY0, c='b')\n",
        "plt.scatter(pointX1, pointY1, c='r')\n",
        "plt.tight_layout()\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqqLOKHkCI_o",
        "colab_type": "text"
      },
      "source": [
        "# **2. Write down the high dimensional function g(x,y;θ) [2pt]**\n",
        "\n",
        "- write down the equation for the non-linear function g(x,y;θ) used for the classifier in LaTeX format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJW9KhFyKgRd",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "g(x, y; \\theta) = \\theta_0f_0(x, y) + \\theta_1f_1(x, y) + ⋯ + \\theta_{k-1}f_{k-1}(x, y)\\\\\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "g(x, y; \\theta) = \\theta_0 + \\theta_1x + \\theta_2y + \\theta_3x^2 + \\theta_4xy + \\theta_5y^2 + \\theta_6x^3 + \\theta_7x^2y + \\theta_8xy^2 + \\theta_9y^3 + \\theta_{10}x^4 + \\theta_{11}x^3y + \\theta_{12}x^2y^2 + \\theta_{13}xy^3 + \\theta_{14}y^4 + \\theta_{15}x^5\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mujVAKAmCNjP",
        "colab_type": "text"
      },
      "source": [
        "# **3. Plot the training error [3pt]**\n",
        "\n",
        "- plot the training error J(θ) at every iteration of gradient descent until convergence (in blue color)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mEMEUWYDPWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "783e8dd0-b7d3-4a51-9631-25d970d518bf"
      },
      "source": [
        "X = pointX #전체 x\n",
        "y = np.array(pointY,dtype=float)\n",
        "label = np.array(label,dtype=float)\n",
        "print(len(y))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNLXbC6gS51L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def g_function(X, y, theta, it, i):\n",
        "  return  (theta[0][it] + theta[1][it]*X[i] + theta[2][it]*y[i] + theta[3][it]*X[i]*X[i] +\n",
        "          theta[4][it]*X[i]*y[i] + theta[5][it]*y[i]*y[i] + theta[6][it]*X[i]*X[i]*X[i] + theta[7][it]*X[i]*X[i]*y[i] +\n",
        "          theta[8][it]*X[i]*y[i]*y[i] + theta[9][it]*y[i]*y[i]*y[i] + theta[10][it]*X[i]*X[i]*X[i]*X[i] + theta[11][it]*X[i]*X[i]*X[i]*y[i] +\n",
        "          theta[12][it]*X[i]*X[i]*y[i]*y[i] + theta[13][it]*X[i]*y[i]*y[i]*y[i] + theta[14][it]*y[i]*y[i]*y[i]*y[i] + theta[15][it]*X[i]*X[i]*X[i]*X[i]*X[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nlfxBVRQEQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(X,y,label,theta,learning_rate=0.0000001,iterations=1000):\n",
        "    \n",
        "    m = len(y)\n",
        "\n",
        "    cost_history = np.zeros(iterations)\n",
        "    theta_history = np.zeros((iterations,16))\n",
        "    for it in range(iterations):\n",
        "        pred = 0\n",
        "\n",
        "        pred0 = 0\n",
        "        pred1 = 0\n",
        "        pred2 = 0\n",
        "        pred3 = 0\n",
        "        pred4 = 0\n",
        "        pred5 = 0\n",
        "        pred6 = 0\n",
        "        pred7 = 0\n",
        "        pred8 = 0\n",
        "        pred9 = 0\n",
        "        pred10 = 0\n",
        "        pred11 = 0\n",
        "        pred12 = 0\n",
        "        pred13 = 0\n",
        "        pred14 = 0\n",
        "        pred15 = 0\n",
        "\n",
        "        for i in range(0, m):\n",
        "          # print(i)\n",
        "          #cost 함수\n",
        "          pred = pred + ((-1)*label[i]*math.log(1/(1 + math.exp((-1)*g_function(X, y, theta, it, i))))-((1-label[i])*math.log(1 - (-1)*(1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))))))\n",
        "          \n",
        "          #  σ(z)   =    (1/(1 + math.exp((-1)*(theta[0][it] + theta[1][it]*X[i] + theta[2][it]*y[i]))))\n",
        "\n",
        "          #theta함수\n",
        "          pred0 = pred0 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])\n",
        "          pred1 = pred1 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*X[i]\n",
        "          pred2 = pred2 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*y[i]\n",
        "          pred3 = pred3 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*X[i]*X[i]\n",
        "          pred4 = pred4 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*X[i]*y[i]\n",
        "          pred5 = pred5 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*y[i]*y[i]\n",
        "          pred6 = pred6 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*X[i]*X[i]*X[i]\n",
        "          pred7 = pred7 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*X[i]*X[i]*y[i]\n",
        "          pred8 = pred8 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*X[i]*y[i]*y[i]\n",
        "          pred9 = pred9 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*y[i]*y[i]*y[i]\n",
        "          pred10 = pred10 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*X[i]*X[i]*X[i]*X[i]\n",
        "          pred11 = pred11 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*X[i]*X[i]*X[i]*y[i]\n",
        "          pred12 = pred12 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*X[i]*X[i]*y[i]*y[i]\n",
        "          pred13 = pred13 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*X[i]*y[i]*y[i]*y[i]\n",
        "          pred14 = pred14 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*y[i]*y[i]*y[i]*y[i]\n",
        "          pred15 = pred15 + ((1/(1 + math.exp((-1)*g_function(X, y, theta, it, i)))) - label[i])*X[i]*X[i]*X[i]*X[i]*X[i]\n",
        "        \n",
        "        theta[0][it + 1] = theta[0][it] - (1/m)*learning_rate*pred0\n",
        "        theta[1][it + 1] = theta[1][it] - (1/m)*learning_rate*pred1\n",
        "        theta[2][it + 1] = theta[2][it] - (1/m)*learning_rate*pred2\n",
        "        theta[3][it + 1] = theta[3][it] - (1/m)*learning_rate*pred3\n",
        "        theta[4][it + 1] = theta[4][it] - (1/m)*learning_rate*pred4\n",
        "        theta[5][it + 1] = theta[5][it] - (1/m)*learning_rate*pred5\n",
        "        theta[6][it + 1] = theta[6][it] - (1/m)*learning_rate*pred6\n",
        "        theta[7][it + 1] = theta[7][it] - (1/m)*learning_rate*pred7\n",
        "        theta[8][it + 1] = theta[8][it] - (1/m)*learning_rate*pred8\n",
        "        theta[9][it + 1] = theta[9][it] - (1/m)*learning_rate*pred9\n",
        "        theta[10][it + 1] = theta[10][it] - (1/m)*learning_rate*pred10\n",
        "        theta[11][it + 1] = theta[11][it] - (1/m)*learning_rate*pred11\n",
        "        theta[12][it + 1] = theta[12][it] - (1/m)*learning_rate*pred12\n",
        "        theta[13][it + 1] = theta[13][it] - (1/m)*learning_rate*pred13\n",
        "        theta[14][it + 1] = theta[14][it] - (1/m)*learning_rate*pred14\n",
        "        theta[15][it + 1] = theta[15][it] - (1/m)*learning_rate*pred15\n",
        "\n",
        "        theta_history[it][0] = theta[0][it]\n",
        "        theta_history[it][1] = theta[1][it]\n",
        "        theta_history[it][2] = theta[2][it]\n",
        "        theta_history[it][3] = theta[3][it]\n",
        "        theta_history[it][4] = theta[4][it]\n",
        "        theta_history[it][5] = theta[5][it]\n",
        "        theta_history[it][6] = theta[6][it]\n",
        "        theta_history[it][7] = theta[7][it]\n",
        "        theta_history[it][8] = theta[8][it]\n",
        "        theta_history[it][9] = theta[9][it]\n",
        "        theta_history[it][10] = theta[10][it]\n",
        "        theta_history[it][11] = theta[11][it]\n",
        "        theta_history[it][12] = theta[12][it]\n",
        "        theta_history[it][13] = theta[13][it]\n",
        "        theta_history[it][14] = theta[14][it]\n",
        "        theta_history[it][15] = theta[15][it]\n",
        "\n",
        "        cost_history[it]  = (1/m) * pred\n",
        "        \n",
        "    return theta, cost_history, theta_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO4LdAVmQG_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr =0.0000001\n",
        "n_iter = 300000\n",
        "\n",
        "theta = np.zeros((16, n_iter + 1))  #theta 전부 0으로 초기화\n",
        "# theta[0][0] = -12.0\n",
        "# theta[1][0] = 0.2\n",
        "# theta[2][0] = -0.2\n",
        "\n",
        "X_b = np.c_[np.ones((len(X),0)),X]\n",
        "X_b = np.array(X_b,dtype=float)\n",
        "# print(X_b.shape)\n",
        "# print(X_b.dtype)\n",
        "# print(y.dtype)\n",
        "theta,cost_history,theta_history = gradient_descent(X_b,y,label,theta,lr,n_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hGch925QUBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fig,ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "theta0_history = []\n",
        "theta1_history = []\n",
        "theta2_history = []\n",
        "theta3_history = []\n",
        "theta4_history = []\n",
        "theta5_history = []\n",
        "theta6_history = []\n",
        "theta7_history = []\n",
        "theta8_history = []\n",
        "theta9_history = []\n",
        "theta10_history = []\n",
        "theta11_history = []\n",
        "theta12_history = []\n",
        "theta13_history = []\n",
        "theta14_history = []\n",
        "theta15_history = []\n",
        "\n",
        "for it in range(n_iter):\n",
        "  theta0_history.append(theta_history[it][0])\n",
        "  theta1_history.append(theta_history[it][1])\n",
        "  theta2_history.append(theta_history[it][2])\n",
        "  theta3_history.append(theta_history[it][3])\n",
        "  theta4_history.append(theta_history[it][4])\n",
        "  theta5_history.append(theta_history[it][5])\n",
        "  theta6_history.append(theta_history[it][6])\n",
        "  theta7_history.append(theta_history[it][7])\n",
        "  theta8_history.append(theta_history[it][8])\n",
        "  theta9_history.append(theta_history[it][9])\n",
        "  theta10_history.append(theta_history[it][10])\n",
        "  theta11_history.append(theta_history[it][11])\n",
        "  theta12_history.append(theta_history[it][12])\n",
        "  theta13_history.append(theta_history[it][13])\n",
        "  theta14_history.append(theta_history[it][14])\n",
        "  theta15_history.append(theta_history[it][15])\n",
        "\n",
        "# ax.set_ylabel('Theta')\n",
        "# ax.set_xlabel('Iterations')\n",
        "# _=ax.plot(range(n_iter),theta0_history,'b.', color = 'red')\n",
        "# _=ax.plot(range(n_iter),theta1_history,'b.', color = 'green')\n",
        "# _=ax.plot(range(n_iter),theta2_history,'b.', color = 'blue')\n",
        "\n",
        "for it in range(0, 16):\n",
        "  print(theta_history[-1][it])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I8EKgyNcWG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "# n_iter = 50\n",
        "# cost_history = new_cost(X_b,y,theta,n_iter)\n",
        "\n",
        "print(cost_history[-1])\n",
        "\n",
        "ax.set_ylabel('J(Theta)')\n",
        "ax.set_xlabel('Iterations')\n",
        "_=ax.plot(range(n_iter),cost_history,'b.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0_y4h3lCOEW",
        "colab_type": "text"
      },
      "source": [
        "# **4. Plot the training accuracy [3pt]**\n",
        "\n",
        "- plot the training accuracy at every iteration of gradient descent until convergence (in red color)\n",
        "- the score will be given depending on the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wj0uBA9DPzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv_zAWupCOVI",
        "colab_type": "text"
      },
      "source": [
        "# **5. Write down the final training accuracy [5pt]**\n",
        "\n",
        "- present the final training accuracy in number (%) at convergence\n",
        "- the score will be given depending on the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S_-z50iDQWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MokllgPaCOmA",
        "colab_type": "text"
      },
      "source": [
        "# **6. Plot the optimal classifier superimposed on the training data [5pt]**\n",
        "\n",
        "- plot the boundary of the optimal classifier at convergence (in green color)\n",
        "- the boundary of the classifier is defined by {(x,y)∣σ(g(x,y;θ))=0.5}={(x,y)∣g(x,y;θ)=0}\n",
        "- plot the training data points (x,y) with their labels lll in colors superimposed on the illustration of the classifier (blue for label 0 and red for label 1)\n",
        "- you can use contour function in python3\n",
        "- the score will be given depending on the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FDAbh1m9VU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}